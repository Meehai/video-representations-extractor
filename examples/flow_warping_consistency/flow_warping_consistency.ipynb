{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"VRE_COLORIZE_SEMSEG_FAST\"] = \"1\"\n",
    "import torch as tr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from vre.utils import get_project_root, lo, colorize_semantic_segmentation, image_resize_batch\n",
    "from vre import FFmpegVideo\n",
    "from vre.representations import Representation, IORepresentationMixin\n",
    "from vre_repository.optical_flow.raft import FlowRaft\n",
    "from vre_repository.semantic_segmentation.safeuav import SafeUAV\n",
    "\n",
    "device = \"cpu\"#\"cuda\" if tr.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_torch(image: tr.Tensor, flow: tr.Tensor) -> tr.Tensor:\n",
    "    H, W = image.shape[-2:]\n",
    "    # Create normalized meshgrid [-1,1] for grid_sample\n",
    "    lsw, lsh =  tr.linspace(-1, 1, W, device=image.device), tr.linspace(-1, 1, H, device=image.device),\n",
    "    grid_x, grid_y = tr.meshgrid(lsw, lsh, indexing=\"xy\")\n",
    "    grid = tr.stack((grid_x, grid_y), dim=-1)  # (H, W, 2), normalized [-1, 1]\n",
    "    # Apply flow directly (since it's already in [-1, 1] range)\n",
    "    new_grid = grid - flow\n",
    "    # Warp image using grid_sample\n",
    "    warped = F.grid_sample(image, new_grid, mode=\"bilinear\", align_corners=True)\n",
    "    return warped\n",
    "\n",
    "def warp_image(rgb_t: np.ndarray, flow: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    rgb_t :: (B, H, W, 3) uint8 [0:255]\n",
    "    flow :: (B, H, W, 2) float32 [-1:-1]\n",
    "    \"\"\"\n",
    "    image = (tr.tensor(rgb_t).permute(0, 3, 1, 2).float() / 255).to(device)\n",
    "    flow = tr.tensor(flow).float().to(device)\n",
    "    warped = warp_torch(image, flow)\n",
    "    warped_numpy = (warped.permute(0, 2, 3, 1) * 255).cpu().numpy().astype(np.uint8)\n",
    "    return warped_numpy\n",
    "\n",
    "def mm(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = FFmpegVideo(get_project_root() / \"resources/test_video.mp4\")\n",
    "print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = video.shape[1:3]\n",
    "safeuav = SafeUAV(name=\"safeuav\", dependencies=[], disk_data_argmax=True, variant=\"model_4M\")\n",
    "raft_r = FlowRaft(name=\"flow_raft\", dependencies=[], inference_width=w, inference_height=h, iters=5,\n",
    "                  small=False, delta=1)\n",
    "raft_l = FlowRaft(name=\"flow_raft\", dependencies=[], inference_width=w, inference_height=h, iters=5,\n",
    "                  small=False, delta=-1)\n",
    "raft_r.device = raft_l.device = safeuav.device = device\n",
    "raft_r.vre_setup() if raft_r.setup_called is False else None\n",
    "raft_l.vre_setup() if raft_l.setup_called is False else None\n",
    "safeuav.vre_setup() if safeuav.setup_called is False else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = 1\n",
    "delta = 10\n",
    "raft_r.delta = delta\n",
    "raft_l.delta = -delta\n",
    "\n",
    "ixs = sorted([np.random.randint(delta, len(video) - delta - 1) for _ in range(mb)])\n",
    "# ixs = [4000]\n",
    "ixs_l = [ix + raft_l.delta for ix in ixs]\n",
    "ixs_r = [ix + raft_r.delta for ix in ixs]\n",
    "print(f\"{ixs=}, {ixs_l=}, {ixs_r=}\")\n",
    "\n",
    "rgbs, rgbs_l, rgbs_r = video[ixs], video[ixs_l], video[ixs_r] # (B, H, W, 3)\n",
    "\n",
    "flow_l_out = raft_l.resize(raft_l.compute(video, ixs_l), video.shape[1:3]) # (B, H, W, 2)\n",
    "flow_l_img = raft_l.make_images(flow_l_out) # (B, H, W, 3)\n",
    "flow_r_out = raft_r.resize(raft_r.compute(video, ixs_r), video.shape[1:3]) # (B, H, W, 2)\n",
    "flow_r_img = raft_r.make_images(flow_r_out) # (B, H, W, 3)\n",
    "\n",
    "rgb_warp_l = warp_image(rgbs, flow_l_out.output) # (B, H, W, 3)\n",
    "rgb_warp_r = warp_image(rgbs, flow_r_out.output) # (B, H, W, 3)\n",
    "mask_l = rgb_warp_l.sum(-1, keepdims=True) != 0 # (B, H, W, 1)\n",
    "mask_r = rgb_warp_r.sum(-1, keepdims=True) != 0 # (B, H, W, 1)\n",
    "\n",
    "diffs_l = ((rgbs_l.astype(np.float32) - rgb_warp_l).__abs__() * mask_l).sum(-1) # (B, H, W)\n",
    "diffs_r = ((rgbs_r.astype(np.float32) - rgb_warp_r).__abs__() * mask_r).sum(-1) # (B, H, W)\n",
    "\n",
    "sema_out = safeuav.resize(safeuav.compute(video, ixs), video.shape[1:3]) # (B, H, W, C)\n",
    "sema_img = safeuav.make_images(sema_out) # (B, H, W, 3)\n",
    "sema_out_l = safeuav.resize(safeuav.compute(video, ixs_l), video.shape[1:3]) # (B, H, W, C)\n",
    "sema_img_l = safeuav.make_images(sema_out_l) # (B, H, W, 3)\n",
    "sema_out_r = safeuav.resize(safeuav.compute(video, ixs_r), video.shape[1:3]) # (B, H, W, C)\n",
    "sema_img_r = safeuav.make_images(sema_out_r) # (B, H, W, 3)\n",
    "\n",
    "sema_warp_l = warp_torch(tr.from_numpy(sema_out.output).permute(0, 3, 1, 2), tr.from_numpy(flow_l_out.output)).permute(0, 2, 3, 1).numpy().argmax(-1) # (B, H, W) argmax\n",
    "sema_warp_r = warp_torch(tr.from_numpy(sema_out.output).permute(0, 3, 1, 2), tr.from_numpy(flow_r_out.output)).permute(0, 2, 3, 1).numpy().argmax(-1) # (B, H, W) argmax\n",
    "sema_warp_l_img = colorize_semantic_segmentation(sema_warp_l, safeuav.classes, safeuav.color_map) * mask_l # (B, H, W, 3)\n",
    "sema_warp_r_img = colorize_semantic_segmentation(sema_warp_r, safeuav.classes, safeuav.color_map) * mask_r # (B, H, W, 3)\n",
    "red_cm = np.array([[0, 0, 0], [255, 0, 0]])\n",
    "black = rgbs[0] * 0\n",
    "diff_sema_l = ((sema_out_l.output.argmax(-1) != sema_warp_l) * mask_l[..., 0]).astype(int) # (B, H, W)\n",
    "diff_sema_r = ((sema_out_r.output.argmax(-1) != sema_warp_r) * mask_r[..., 0]).astype(int) # (B, H, W)\n",
    "score = 1 - (diff_sema_l + diff_sema_r) / 2 # (B, H, W)\n",
    "\n",
    "for i in range(mb):\n",
    "    fig, ax = plt.subplots(3, 6, figsize=(20, 8))\n",
    "    fig.suptitle(f\"Consistency score: {score[i].mean() * 100:.2f}%\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 0].set_title(f\"T={ixs_l[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 0].imshow(rgbs_l[i])\n",
    "    ax[0, 1].set_title(f\"warp {ixs[i]}->{ixs_l[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 1].imshow(rgb_warp_l[i].round().astype(np.uint8))\n",
    "    ax[0, 2].set_title(f\"Diff: {diffs_l.mean().item():.2f}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 2].imshow(mm(diffs_l[i]))\n",
    "    ax[0, 3].set_title(f\"Sema T={ixs_l[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 3].imshow(sema_img_l[i])\n",
    "    ax[0, 4].set_title(f\"warp {ixs[i]}->{ixs_l[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 4].imshow(sema_warp_l_img[i])\n",
    "    ax[0, 5].set_title(f\"Diff: {diff_sema_l[i].mean()*100:.2f}%\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[0, 5].imshow(red_cm[diff_sema_l[i]])\n",
    "\n",
    "    ax[1, 0].set_title(f\"T={ixs[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[1, 0].imshow(video[ixs[i]])\n",
    "    ax[1, 1].set_title(f\"flow {ixs[i]}->{ixs_l[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[1, 1].imshow(flow_l_img[i])\n",
    "    ax[1, 2].set_title(f\"flow {ixs[i]}->{ixs_r[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[1, 2].imshow(flow_r_img[i])\n",
    "    ax[1, 3].imshow(black)\n",
    "    ax[1, 4].set_title(f\"sema {ixs[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[1, 4].imshow(sema_img[i])\n",
    "    ax[1, 5].imshow(black)\n",
    "\n",
    "    ax[2, 0].set_title(f\"T={ixs_r[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 0].imshow(rgbs_r[i])\n",
    "    ax[2, 1].set_title(f\"warp {ixs[i]}->{ixs_r[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 1].imshow(rgb_warp_r[i].round().astype(np.uint8))\n",
    "    ax[2, 2].set_title(f\"Diff: {diffs_r.mean().item():.2f}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 2].imshow(mm(diffs_r[i]))\n",
    "    ax[2, 3].set_title(f\"Sema T={ixs_r[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 3].imshow(sema_img_r[i])\n",
    "    ax[2, 4].set_title(f\"warp {ixs[i]}->{ixs_r[i]}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 4].imshow(sema_warp_r_img[i])\n",
    "    ax[2, 5].set_title(f\"Diff: {diff_sema_r[i].mean() * 100:.2f}%\", fontsize=14, fontweight=\"bold\")\n",
    "    ax[2, 5].imshow(red_cm[diff_sema_r[i]])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
