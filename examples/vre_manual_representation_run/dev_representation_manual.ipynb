{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as tr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "from vre.representations import build_representations_from_cfg\n",
    "from vre.utils import get_project_root\n",
    "from vre import FFmpegVideo\n",
    "from vre_repository import get_vre_repository\n",
    "from vre_repository.optical_flow.raft import FlowRaft\n",
    "\n",
    "device = \"cuda\" if tr.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = FFmpegVideo(get_project_root() / \"resources/test_video.mp4\")\n",
    "print(video.shape, video.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"VRE_DEVICE\"] = device = \"cuda\" if tr.cuda.is_available() else \"cpu\"\n",
    "# all_representations_dict = OmegaConf.load(open(Path.cwd() / \"cfg.yaml\", \"r\"))\n",
    "\n",
    "# device = \"cuda\" if tr.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# representations = build_representations_from_cfg(all_representations_dict, representation_types=get_vre_repository())\n",
    "# name_to_repr = {r.name: r for r in representations}\n",
    "# print(representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the representations for two particular frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inference setup (this is done inside VRE's main loop at run() as well)\n",
    "# depth, normals = name_to_repr[\"depth_marigold\"], name_to_repr[\"normals_svd(depth_marigold)\"]\n",
    "# depth.vre_setup() if depth.setup_called is False else None\n",
    "\n",
    "# np.random.seed(43)\n",
    "# mb = 2\n",
    "# ixs = sorted([np.random.randint(0, len(video) - 1) for _ in range(mb)])\n",
    "# print(ixs)\n",
    "\n",
    "# depth.data = normals.data = None\n",
    "# depth.compute(video, ixs)\n",
    "# normals.compute(video, ixs)\n",
    "# y_depth_img = depth.make_images(depth.data)\n",
    "# y_normals_img = normals.make_images(normals.data)\n",
    "# for i in range(mb):\n",
    "#     fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "#     ax[0].imshow(depth.data.frames[i])\n",
    "#     ax[1].imshow(y_depth_img[i])\n",
    "#     ax[2].imshow(y_normals_img[i])\n",
    "#     plt.show()\n",
    "# depth.vre_free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical flow +/-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = video.shape[1:3]\n",
    "# h, w = [540, 960]\n",
    "print(h, w)\n",
    "flow = FlowRaft(name=\"flow_raft\", dependencies=[], inference_width=w, inference_height=h, iters=5,\n",
    "                small=False, delta=1)\n",
    "flow_l = FlowRaft(name=\"flow_raft\", dependencies=[], inference_width=w, inference_height=h, iters=5,\n",
    "                small=False, delta=-1)\n",
    "flow.device = flow_l.device = device\n",
    "print(flow)\n",
    "flow.vre_setup() if flow.setup_called is False else None\n",
    "flow_l.vre_setup() if flow_l.setup_called is False else None\n",
    "\n",
    "# np.random.seed(43)\n",
    "mb = 2\n",
    "ixs = sorted([np.random.randint(0, len(video) - 1) for _ in range(mb)])\n",
    "print(ixs)\n",
    "\n",
    "flow.data = flow_l.data = None\n",
    "flow.compute(video, ixs)\n",
    "flow_l.compute(video, ixs)\n",
    "print(flow.data.output.reshape(-1, 2).mean(0) * [h, w], flow.data.output.reshape(-1, 2).std(0))\n",
    "print(flow_l.data.output.reshape(-1, 2).mean(0)  * [h, w], flow_l.data.output.reshape(-1, 2).std(0))\n",
    "flow_img = flow.make_images(flow.data)\n",
    "flow_l_img = flow_l.make_images(flow_l.data)\n",
    "for i in range(mb):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    # assert (flow.data.output[i] - flow_l.data.output[i]).__abs__().mean() > 1e-3\n",
    "    ax[0].imshow(video[ixs[i]])\n",
    "    ax[1].imshow(flow_img[i])\n",
    "    ax[2].imshow(flow_l_img[i])\n",
    "plt.show()\n",
    "flow.vre_free()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
