rgb:
  type: default
  method: rgb
  dependencies: []
  parameters: null

hsv:
  type: default
  method: hsv
  dependencies: []
  parameters: null

halftone1:
  type: soft-segmentation
  method: python-halftone
  dependencies: []
  parameters:
    sample: 3
    scale: 1
    percentage: 91
    angles: [0, 15, 30, 45]
    antialias: False
    resolution: 240,426

edges dexined:
  type: edges
  method: dexined
  dependencies: []
  parameters: null

edges canny:
  type: edges
  method: canny
  dependencies: []
  parameters:
    threshold1: 150
    threshold2: 200
    apertureSize: 3
    L2gradient: False

softseg kmeans:
  type: soft-segmentation
  method: kmeans
  dependencies: []
  parameters:
    nClusters: 6
    epsilon: 2
    maxIterations: 10
    attempts: 3

softseg gb:
  type: soft-segmentation
  method: generalized_boundaries
  dependencies: []
  parameters:
    useFiltering: True
    adjustToRGB: True
    maxChannels: 3

semantic safeuav torch:
  type: semantic
  method: safeuav
  dependencies: []
  saveResults: resized_only
  parameters:
    weightsFile: safeuav_semantic_0956_pytorch.ckpt
    trainHeight: 240
    trainWidth: 428
    numClasses: 8
    colorMap: [
      [0, 255, 0],
      [0, 127, 0],
      [255, 255, 0],
      [255, 255, 255],
      [255, 0, 0],
      [0, 0, 255],
      [0, 255, 255],
      [127, 127, 63]
    ]

# semantic safeuav keras:
#   type: semantic
#   method: safeuav-keras
#   dependencies: []
#   saveResuts: resized_only
#   parameters:
#     weightsFile: safeuav_semantic_keras.hdf5
#     init_nb: 16
#     trainHeight: 480
#     trainWidth: 856
#     numClasses: 11
#     colorMap: [
#       [0, 255, 0], [0, 127, 0], [255, 255, 0], [255, 255, 255], [255, 0, 255],
#       [127, 127, 127], [0, 0, 255], [0, 255, 255], [127, 127, 63], [255, 0, 0], [127, 127, 0]
#     ]

opticalflow rife:
  type: optical-flow
  method: rife
  dependencies: []
  parameters:
    computeBackwardFlow: False

depth odoflow (rife):
  type: depth
  method: odo-flow
  dependencies: [ opticalflow rife ]
  parameters:
      velocitiesPath: DJI_0956_velocities.npz
      linearAngVelCorrection: True
      focusCorrection: True
      cosineCorrectionScipy: False
      cosineCorrectionGD: True
      fov: 75
      sensorWidth: 3840
      sensorHeight: 2160
      minDepthMeters: 0
      maxDepthMeters: 400

normals svd (rife):
  type: normals
  method: depth-svd
  dependencies: [depth odoflow (rife)]
  parameters:
    fov: 75
    sensorWidth: 3840
    sensorHeight: 2160
    windowSize: 11

opticalflow raft:
  type: optical-flow
  method: raft
  dependencies: []
  parameters:
    inputHeight: 720
    inputWidth: 1280

depth odoflow (raft):
  type: depth
  method: odo-flow
  dependencies: [opticalflow raft]
  parameters:
      velocitiesPath: DJI_0956_velocities.npz
      linearAngVelCorrection: True
      focusCorrection: True
      cosineCorrectionScipy: False
      cosineCorrectionGD: True
      fov: 75
      sensorWidth: 3840
      sensorHeight: 2160
      minDepthMeters: 0
      maxDepthMeters: 400

normals svd (raft):
  type: normals
  method: depth-svd
  dependencies: [depth odoflow (raft)]
  parameters:
    fov: 75
    sensorWidth: 3840
    sensorHeight: 2160
    windowSize: 11
